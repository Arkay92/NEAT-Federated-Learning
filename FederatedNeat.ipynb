{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59DWTFp7zWag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801d2f42-1d13-456a-b8fe-cb43d49cc0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ****** Running generation 0 ****** \n",
            "\n",
            "Population's average fitness: -111.67020 stdev: 10.29272\n",
            "Best fitness: -68.74115 - size: (4, 96) - species 1 - id 44\n",
            "Average adjusted fitness: 0.351\n",
            "Mean genetic distance 1.182, standard deviation 0.217\n",
            "Population of 100 members in 1 species:\n",
            "   ID   age  size  fitness  adj fit  stag\n",
            "  ====  ===  ====  =======  =======  ====\n",
            "     1    0   100    -68.7    0.351     0\n",
            "Total extinctions: 0\n",
            "Generation time: 86.308 sec\n",
            "\n",
            " ****** Running generation 1 ****** \n",
            "\n",
            "Population's average fitness: -109.68041 stdev: 12.94463\n",
            "Best fitness: -65.37075 - size: (4, 95) - species 1 - id 180\n",
            "Average adjusted fitness: 0.348\n",
            "Mean genetic distance 1.286, standard deviation 0.219\n",
            "Population of 100 members in 1 species:\n",
            "   ID   age  size  fitness  adj fit  stag\n",
            "  ====  ===  ====  =======  =======  ====\n",
            "     1    1   100    -65.4    0.348     0\n",
            "Total extinctions: 0\n",
            "Generation time: 103.188 sec (94.748 average)\n",
            "\n",
            " ****** Running generation 2 ****** \n",
            "\n",
            "Population's average fitness: -107.11436 stdev: 12.66278\n",
            "Best fitness: -65.08611 - size: (4, 95) - species 1 - id 180\n",
            "Average adjusted fitness: 0.380\n",
            "Mean genetic distance 1.449, standard deviation 0.234\n",
            "Population of 100 members in 1 species:\n",
            "   ID   age  size  fitness  adj fit  stag\n",
            "  ====  ===  ====  =======  =======  ====\n",
            "     1    2   100    -65.1    0.380     0\n",
            "Total extinctions: 0\n",
            "Generation time: 113.160 sec (100.885 average)\n",
            "\n",
            " ****** Running generation 3 ****** \n",
            "\n",
            "Population's average fitness: -103.63699 stdev: 18.14740\n",
            "Best fitness: -43.54566 - size: (4, 93) - species 1 - id 312\n",
            "Average adjusted fitness: 0.333\n",
            "Mean genetic distance 1.468, standard deviation 0.239\n",
            "Population of 100 members in 1 species:\n",
            "   ID   age  size  fitness  adj fit  stag\n",
            "  ====  ===  ====  =======  =======  ====\n",
            "     1    3   100    -43.5    0.333     0\n",
            "Total extinctions: 0\n",
            "Generation time: 114.108 sec (104.191 average)\n",
            "\n",
            " ****** Running generation 4 ****** \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install python3-dev python3-pip python3-setuptools gcc libffi-dev libssl-dev\n",
        "\n",
        "# !pip install tensorflow tensorflow-federated gym numpy matplotlib swig box2d-py gym[box2d] neat --no-cache-dir\n",
        "# !pip install --upgrade tensorflow_probability tensorflow_model_optimization tensorflow-estimator==2.3.0\n",
        "# !pip install --upgrade tensorflow tensorflow-federated\n",
        "\n",
        "import warnings\n",
        "import neat\n",
        "import gym\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import concurrent.futures\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "config_path = './neat_config.txt'\n",
        "best_genome_path = './best_genome.pkl'\n",
        "demo_file = './demonstrations.pkl'\n",
        "\n",
        "# Define a custom Keras layer for NEAT network\n",
        "class NEATLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, neat_network, **kwargs):\n",
        "        super(NEATLayer, self).__init__(**kwargs)\n",
        "        self.neat_network = neat_network\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = tf.vectorized_map(lambda x: tf.convert_to_tensor(self.neat_network.activate(x.numpy().tolist())), inputs)\n",
        "        return outputs\n",
        "\n",
        "# Federated Learning Testing and Benchmarking Class\n",
        "class FederatedLearningTest:\n",
        "    def __init__(self, clients, model_fn, trainer, state, config, demonstrations):\n",
        "        self.clients = clients\n",
        "        self.model_fn = model_fn\n",
        "        self.trainer = trainer\n",
        "        self.state = state\n",
        "        self.config = config\n",
        "        self.demonstrations = demonstrations\n",
        "\n",
        "    def run_federated_training(self, rounds=10):\n",
        "        metrics_list = []\n",
        "        for round_num in range(rounds):\n",
        "            client_data = [collect_client_data(client[0], client[1]) for client in self.clients]\n",
        "            result = self.trainer.next(self.state, client_data)\n",
        "            self.state = result.state\n",
        "            metrics_list.append(result.metrics)\n",
        "            logger.info(f'Round {round_num} metrics: {result.metrics}')\n",
        "        return metrics_list\n",
        "\n",
        "    def evaluate_model(self, env, network, episodes=10):\n",
        "        total_reward = 0\n",
        "        for _ in range(episodes):\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = np.clip(network.activate(state), -1, 1)\n",
        "                state, reward, done, _ = env.step(action)\n",
        "                total_reward += reward\n",
        "        return total_reward / episodes\n",
        "\n",
        "    def plot_metrics(self, metrics_list):\n",
        "        rounds = range(len(metrics_list))\n",
        "        mse = [metrics['mean_squared_error'].numpy() for metrics in metrics_list]\n",
        "        plt.figure(figsize=(10, 3))\n",
        "        plt.plot(rounds, mse, label='Mean Squared Error')\n",
        "        plt.xlabel('Rounds')\n",
        "        plt.ylabel('Mean Squared Error')\n",
        "        plt.title('Federated Learning Training Metrics')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_rewards(self, rewards):\n",
        "        plt.figure(figsize=(10, 3))\n",
        "        plt.plot(range(len(rewards)), rewards, label='Rewards')\n",
        "        plt.xlabel('Episodes')\n",
        "        plt.ylabel('Rewards')\n",
        "        plt.title('Model Rewards Over Episodes')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def benchmark(self, baseline_reward):\n",
        "        neat_network = neat.nn.FeedForwardNetwork.create(pickle.load(open(best_genome_path, 'rb')), self.config)\n",
        "        client_rewards = [self.evaluate_model(client[0], neat_network) for client in self.clients]\n",
        "        avg_reward = np.mean(client_rewards)\n",
        "\n",
        "        logger.info(f'Average reward after federated learning: {avg_reward}')\n",
        "        logger.info(f'Baseline reward: {baseline_reward}')\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10, 3))\n",
        "        plt.bar(['Baseline', 'Federated Learning'], [baseline_reward, avg_reward])\n",
        "        plt.ylabel('Average Reward')\n",
        "        plt.title('Benchmarking')\n",
        "        plt.show()\n",
        "\n",
        "# Helper function to create environments and networks for each client\n",
        "def create_environment_and_network(client_id, variation, config):\n",
        "    env = gym.make('BipedalWalker-v3')\n",
        "    env._max_episode_steps = 1000\n",
        "    env.env.gravity = variation * client_id\n",
        "    genome = load_genome('best_genome.pkl')\n",
        "    network = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "    return env, network\n",
        "\n",
        "def create_neat_config(path):\n",
        "    config_content = \"\"\"\n",
        "    [NEAT]\n",
        "    fitness_criterion = max\n",
        "    fitness_threshold = 300\n",
        "    pop_size = 100\n",
        "    reset_on_extinction = False\n",
        "    [DefaultGenome]\n",
        "    num_hidden = 0\n",
        "    num_inputs = 24\n",
        "    num_outputs = 4\n",
        "    initial_connection = full\n",
        "    activation_default = tanh\n",
        "    activation_mutate_rate = 0.1\n",
        "    activation_options = tanh relu sigmoid\n",
        "    aggregation_default = sum\n",
        "    aggregation_mutate_rate = 0.0\n",
        "    aggregation_options = sum\n",
        "    bias_init_mean = 0.0\n",
        "    bias_init_stdev = 1.0\n",
        "    bias_max_value = 30.0\n",
        "    bias_min_value = -30.0\n",
        "    bias_mutate_power = 0.5\n",
        "    bias_mutate_rate = 0.7\n",
        "    bias_replace_rate = 0.1\n",
        "    response_init_mean = 1.0\n",
        "    response_init_stdev = 0.0\n",
        "    response_max_value = 30.0\n",
        "    response_min_value = -30.0\n",
        "    response_mutate_power = 0.0\n",
        "    response_mutate_rate = 0.0\n",
        "    response_replace_rate = 0.0\n",
        "    compatibility_disjoint_coefficient = 1.0\n",
        "    compatibility_weight_coefficient = 0.5\n",
        "    conn_add_prob = 0.5\n",
        "    conn_delete_prob = 0.5\n",
        "    enabled_default = True\n",
        "    enabled_mutate_rate = 0.01\n",
        "    feed_forward = True\n",
        "    node_add_prob = 0.2\n",
        "    node_delete_prob = 0.2\n",
        "    weight_init_mean = 0.0\n",
        "    weight_init_stdev = 1.0\n",
        "    weight_max_value = 30\n",
        "    weight_min_value = -30\n",
        "    weight_mutate_power = 0.5\n",
        "    weight_mutate_rate = 0.8\n",
        "    weight_replace_rate = 0.1\n",
        "    [DefaultSpeciesSet]\n",
        "    compatibility_threshold = 3.0\n",
        "    [DefaultStagnation]\n",
        "    species_fitness_func = max\n",
        "    max_stagnation = 20\n",
        "    species_elitism = 2\n",
        "    [DefaultReproduction]\n",
        "    elitism = 2\n",
        "    survival_threshold = 0.2\n",
        "    [SteadyState]\n",
        "    replacement_rate = 0.2\n",
        "    \"\"\"\n",
        "    with open(path, 'w') as config_file:\n",
        "        config_file.write(config_content.strip())\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    logger.info(f\"Configuration file '{config_path}' not found. Creating default configuration file.\")\n",
        "    create_neat_config(config_path)\n",
        "else:\n",
        "    logger.info(\"Configuration file exists. Overwriting with correct format.\")\n",
        "    create_neat_config(config_path)\n",
        "\n",
        "try:\n",
        "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_path)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to load NEAT configuration: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Evaluate genomes function with reinforcement learning from demonstrations (RLfD), Parallel processing of genomes evaluation\n",
        "def evaluate_genome(genome_id, genome, config):\n",
        "    env = gym.make('BipedalWalker-v3')\n",
        "    env._max_episode_steps = 1000\n",
        "    net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "    fitness = 0\n",
        "    try:\n",
        "        for _ in range(3):  # Average performance over multiple episodes\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = np.clip(net.activate(state), -1, 1)\n",
        "                state, reward, done, _ = env.step(action)\n",
        "                fitness += reward\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error evaluating genome {genome_id}: {e}\")\n",
        "    return fitness / 3, genome\n",
        "\n",
        "def evaluate_genomes(genomes, config):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
        "        futures = [executor.submit(evaluate_genome, genome_id, genome, config) for genome_id, genome in genomes]\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            fitness, genome = future.result()\n",
        "            genome.fitness = fitness\n",
        "\n",
        "# TensorFlow Federated model function using the NEAT genome\n",
        "def model_fn():\n",
        "    genome = load_genome('best_genome.pkl')\n",
        "    config_path = './neat_config.txt'\n",
        "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_path)\n",
        "    neat_network = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "    model = tf.keras.Sequential([\n",
        "        NEATLayer(neat_network),\n",
        "        tf.keras.layers.Dense(units=4, activation='tanh')\n",
        "    ])\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=model,\n",
        "        input_spec=(tf.TensorSpec(shape=[None, 24], dtype=tf.float32), tf.TensorSpec(shape=[None], dtype=tf.float32)),\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "# Collect client data for federated learning using Gym environments\n",
        "def collect_client_data(environment, net, episodes=10):\n",
        "    data = []\n",
        "    for _ in range(episodes):\n",
        "        state = environment.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = np.clip(net.activate(state), -1, 1)\n",
        "            next_state, reward, done, _ = environment.step(action)\n",
        "            data.append((state, action, reward, next_state, done))\n",
        "            state = next_state\n",
        "    states, actions, rewards, next_states, dones = zip(*data)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((np.array(states), np.array(actions)))\n",
        "    return dataset.batch(32)\n",
        "\n",
        "# Create demonstrations for reinforcement learning, saved as pickle\n",
        "if not os.path.exists(demo_file):\n",
        "    env_demo = gym.make('BipedalWalker-v3')\n",
        "    demos = []\n",
        "    for _ in range(10):  # Create 10 demonstrations\n",
        "        state = env_demo.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = env_demo.action_space.sample()  # Random actions as placeholders\n",
        "            next_state, _, done, _ = env_demo.step(action)\n",
        "            demos.append((state, action))\n",
        "            state = next_state\n",
        "    with open(demo_file, 'wb') as f:\n",
        "        pickle.dump(demos, f)\n",
        "demonstrations = pickle.load(open(demo_file, 'rb'))\n",
        "\n",
        "def load_genome(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"Error: File '{filepath}' not found. Exiting.\")\n",
        "        raise SystemExit\n",
        "\n",
        "# Evaluate genomes with RLfD using demonstrations\n",
        "def evaluate_with_demos(genomes, config, env, demonstrations):\n",
        "    for genome_id, genome in genomes:\n",
        "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "        fitness = 0\n",
        "        for _ in range(3):\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = np.clip(net.activate(state), -1, 1)\n",
        "                state, reward, done, _ = env.step(action)\n",
        "                fitness += reward\n",
        "        genome.fitness = fitness / 3\n",
        "\n",
        "def client_data(n):\n",
        "    source, _ = tff.simulation.datasets.emnist.load_data()\n",
        "    return source.create_tf_dataset_for_client(source.client_ids[n]).map(\n",
        "        lambda e: (tf.reshape(e['pixels'], [-1]), e['label'])\n",
        "    ).repeat(10).batch(20)\n",
        "\n",
        "def federated_train(num_clients, num_rounds):\n",
        "    clients = [create_environment_and_network(i, 1.0 + 0.1 * i, config) for i in range(num_clients)]\n",
        "    train_data = [client_data(n) for n in range(num_clients)]\n",
        "    model = model_fn()\n",
        "    trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1))\n",
        "    state = trainer.initialize()\n",
        "    for round_num in range(num_rounds):\n",
        "        result = trainer.next(state, train_data)\n",
        "        state = result.state\n",
        "        metrics = result.metrics\n",
        "        logger.info(f'Round {round_num + 1}: {metrics[\"client_work\"][\"train\"][\"accuracy\"]}')\n",
        "\n",
        "    return state, metrics\n",
        "\n",
        "# NEAT training function for non-federated learning\n",
        "def train_neat_non_federated(config, episodes=100):\n",
        "    env = gym.make('BipedalWalker-v3')\n",
        "    env._max_episode_steps = 1000\n",
        "    population = neat.Population(config)\n",
        "    population.add_reporter(neat.StdOutReporter(True))\n",
        "    stats = neat.StatisticsReporter()\n",
        "    population.add_reporter(stats)\n",
        "    winner = population.run(lambda genomes, config: evaluate_genomes(genomes, config), episodes)\n",
        "    return winner, stats\n",
        "\n",
        "# Plotting function for comparing federated and non-federated results\n",
        "def plot_comparison(federated_rewards, non_federated_rewards):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    episodes = range(len(federated_rewards))\n",
        "    plt.plot(episodes, federated_rewards, label='Federated NEAT')\n",
        "    plt.plot(episodes, non_federated_rewards, label='Non-Federated NEAT')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Rewards')\n",
        "    plt.title('Comparison of Federated and Non-Federated NEAT')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "population = neat.Population(config)\n",
        "population.add_reporter(neat.StdOutReporter(True))\n",
        "stats = neat.StatisticsReporter()\n",
        "population.add_reporter(stats)\n",
        "\n",
        "if not os.path.exists(best_genome_path):\n",
        "    winner = population.run(lambda genomes, config: evaluate_genomes(genomes, config))\n",
        "    with open(best_genome_path, 'wb') as f:\n",
        "        pickle.dump(winner, f)\n",
        "\n",
        "# NEAT training incorporating demonstrations\n",
        "winner = population.run(lambda genomes, config: evaluate_with_demos(genomes, config, create_environment_and_network(1, 1.0, config)[0], demonstrations), 30)\n",
        "with open(best_genome_path, 'wb') as f:\n",
        "    pickle.dump(winner, f)\n",
        "\n",
        "# Load simulation data for federated learning\n",
        "source, _ = tff.simulation.datasets.emnist.load_data()\n",
        "\n",
        "# Pick a subset of client devices to participate in training\n",
        "train_data = [client_data(n) for n in range(3)]\n",
        "\n",
        "# Wrap a Keras model for use with TensorFlow Federated\n",
        "# Federated Learning Execution\n",
        "tff_model = model_fn()\n",
        "trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    tff_model,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1))\n",
        "state = trainer.initialize()\n",
        "\n",
        "for _ in range(3):\n",
        "    result = trainer.next(state, train_data)\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    logger.info(metrics['client_work']['train']['accuracy'])\n",
        "\n",
        "# Initialize environments and networks for clients\n",
        "clients = [create_environment_and_network(i, 1.0 + 0.1 * i, config) for i in range(3)]\n",
        "\n",
        "# Federated Learning Trainer Setup\n",
        "trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.legacy.SGD(learning_rate=0.1))\n",
        "state = trainer.initialize()\n",
        "\n",
        "# Testing and benchmarking\n",
        "test = FederatedLearningTest(clients, model_fn, trainer, state, config, demonstrations)\n",
        "\n",
        "# Run federated training\n",
        "state, final_metrics = federated_train(3, 10)\n",
        "\n",
        "# Run non-federated training\n",
        "winner, stats = train_neat_non_federated(config, 100)\n",
        "\n",
        "# Save winner genome\n",
        "with open('winner_genome.pkl', 'wb') as f:\n",
        "    pickle.dump(winner, f)\n",
        "\n",
        "# Evaluate rewards for both methods\n",
        "neat_network = neat.nn.FeedForwardNetwork.create(pickle.load(open(best_genome_path, 'rb')), config)\n",
        "federated_rewards = [test.evaluate_model(client[0], neat_network) for client in clients]\n",
        "non_federated_rewards = [test.evaluate_model(client[0], neat_network, 100) for client in [winner]] * len(clients)\n",
        "\n",
        "# Plot the comparison of federated vs non-federated training\n",
        "plot_comparison(federated_rewards, non_federated_rewards)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GMSMJWK9cCL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}